{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EG8AQJTofVLX"
      },
      "outputs": [],
      "source": [
        "# Loading datasets and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEdMWFvleRRU",
        "outputId": "85a4d9fe-f10d-4316-bfc5-f374f0fb9456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torcheval\n",
            "  Downloading torcheval-0.0.6-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.4/158.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtnt>=0.0.5\n",
            "  Downloading torchtnt-0.1.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.5.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (2.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (2023.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (4.65.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (5.9.5)\n",
            "Collecting pyre-extensions\n",
            "  Downloading pyre_extensions-0.0.30-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (67.7.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (2.0.0+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (23.1)\n",
            "Collecting typing-inspect\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.54.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (3.4.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.0.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.3.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.27.1)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (3.20.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (0.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (3.12.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtnt>=0.0.5->torcheval) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtnt>=0.0.5->torcheval) (3.25.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (0.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (4.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (1.16.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->torchtnt>=0.0.5->torcheval) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->torchtnt>=0.0.5->torcheval) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtnt>=0.0.5->torcheval) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->torchtnt>=0.0.5->torcheval) (3.2.2)\n",
            "Installing collected packages: mypy-extensions, typing-inspect, pyre-extensions, torchtnt, torcheval\n",
            "Successfully installed mypy-extensions-1.0.0 pyre-extensions-0.0.30 torcheval-0.0.6 torchtnt-0.1.0 typing-inspect-0.8.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imblearn\n",
            "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (from imblearn) (0.10.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.2.0)\n",
            "Installing collected packages: imblearn\n",
            "Successfully installed imblearn-0.0\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from numpy import random\n",
        "#from google.colab import files\n",
        "\n",
        "!pip install torcheval\n",
        "from torcheval.metrics.functional import multiclass_f1_score\n",
        "!pip install imblearn\n",
        "from imblearn.over_sampling import RandomOverSampler # , SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset"
      ],
      "metadata": {
        "id": "J7RH0RXue80Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "bQ9hKQJq_BMM"
      },
      "outputs": [],
      "source": [
        "y = np.loadtxt(\"drive/MyDrive/beforesmotey\")\n",
        "X = np.loadtxt(\"drive/MyDrive/beforesmote\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-gkdPW2qrHv2"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, hidden_dim,mlp_dim, drop):\n",
        "   \n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # Attention\n",
        "        self.attention = nn.MultiheadAttention(embed_dim = hidden_dim, num_heads = 1)\n",
        "        # LSTM layer\n",
        "        self.rnn = nn.LSTM(input_size = 1, hidden_size = hidden_dim, num_layers = 1)\n",
        "        # last, fully-connected layer\n",
        "        self.fc1 = nn.Linear(hidden_dim, mlp_dim) \n",
        "        self.fc2 = nn.Linear(mlp_dim, 5)\n",
        "        self.logsoftmax = nn.LogSoftmax() \n",
        "        self.layer = nn.LayerNorm(hidden_dim)\n",
        "        # Capa dropout \n",
        "        self.dropout = nn.Dropout(p=drop)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # LSTM\n",
        "        _, last_state_tup =  self.rnn(x)\n",
        "        last_state = last_state_tup[0]\n",
        "        # Attention\n",
        "        x = self.attention(last_state,last_state,last_state,need_weights = False)[0]\n",
        "        # Add\n",
        "        #x += last_state\n",
        "\n",
        "        # Normalize\n",
        "        x = self.layer(x)\n",
        "\n",
        "        # MLP with dropout and relu\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # Softmax - not tunable\n",
        "        output = self.logsoftmax(x)\n",
        "        return output\n",
        "\n",
        "    def set_type_test(self, x):\n",
        "\n",
        "        # Dont change it!\n",
        "        x = np.trim_zeros(x, 'b')\n",
        "        x = torch.Tensor(x).view(-1,1)\n",
        "        x = x.to(torch.float32)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "x-WEsaDQzSHP"
      },
      "outputs": [],
      "source": [
        "class RNN_with_train(RNN):\n",
        "    \n",
        "    def __init__(self,hidden_dim, mlp_dim, drop=0.5,weights =[ 1.0,2.3,5,9,5 ] ,batch_size=32,lr=0.0001,saved_files='drive/MyDrive/saved_models/'):\n",
        "        # weights must be floats!\n",
        "\n",
        "        super().__init__(hidden_dim, mlp_dim, drop)  \n",
        "        \n",
        "        self.lr = lr # Learning Rate\n",
        "  \n",
        "        self.optim = optim.Adam(self.parameters(), self.lr) # Optimizer\n",
        "        \n",
        "        self.criterion = nn.NLLLoss(weight = torch.tensor(weights))              \n",
        "        \n",
        "        self.loss_during_training = [] \n",
        "\n",
        "        self.valid_loss_during_training = [] \n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "        self.saved_files = saved_files\n",
        "\n",
        "        # difficult to get it working\n",
        "        #self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        #self.to(self.device)\n",
        "            \n",
        "    def trainloop(self, X, Y, valid = False, X_val= None, Y_val= None,epochs= 40,print_every=1):\n",
        "        \n",
        "        self.print_every = print_every\n",
        "        self.epochs=epochs\n",
        "        n_batch = int(X.shape[0]/self.batch_size)\n",
        "\n",
        "        for e in range(int(self.epochs)):\n",
        "\n",
        "          self.train() # Activate dropout\n",
        "          # random permutation (optional)\n",
        "          id_perm = np.random.permutation(np.arange(X.shape[0]))\n",
        "          for nul in range(n_batch):\n",
        "            # either one - look up random permutation\n",
        "            idx = id_perm[nul*self.batch_size:(nul+1)*self.batch_size]\n",
        "            #idx = random.choice(np.arange(X.shape[0]), self.batch_size) # choose element to train given a label\n",
        "            labels = torch.Tensor(Y[idx]).type(torch.LongTensor)\n",
        "            #labels.to(self.device)\n",
        "            outputs = torch.zeros(self.batch_size,5)\n",
        "            k = 0\n",
        "            for b in idx:\n",
        "\n",
        "              running_loss = 0.\n",
        "              self.optim.zero_grad() \n",
        "              x = X[b,:]\n",
        "              x = np.trim_zeros(x, 'b')\n",
        "              x = torch.Tensor(x).view(-1,1)\n",
        "              x = x.to(torch.float32)\n",
        "              outputs[k, :] = self.forward(x)\n",
        "              k += 1\n",
        "              #print([out, class_number])\n",
        "            #outputs.to(self.device)\n",
        "            loss = self.criterion(outputs ,labels)\n",
        "            running_loss += loss.item()\n",
        "            loss.backward()\n",
        "            # Gradient clipping\n",
        "            nn.utils.clip_grad_norm_(self.parameters(), 2.0)\n",
        "            # SGD steps\n",
        "            self.optim.step()\n",
        "\n",
        "\n",
        "          self.loss_during_training.append(running_loss) # no self batch size to better see\n",
        "          if valid:\n",
        "            self.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "              labels = torch.Tensor(Y_val).type(torch.LongTensor)\n",
        "              #labels = labels.to(self.device)\n",
        "              outputs = torch.zeros(X_val.shape[0],5)\n",
        "              for k in range(X_val.shape[0]):\n",
        "                outputs[k, :] = self.forward_test(X_val[k,:])\n",
        "              #outputs.to(self.device)\n",
        "              loss = self.criterion(outputs ,labels)\n",
        "              running_loss += loss.item()\n",
        "              self.valid_loss_during_training.append(running_loss) # no self batch size to better see\n",
        "              val_F1 = multiclass_f1_score(outputs, labels, num_classes=5, average = \"macro\")\n",
        "          if(e % self.print_every == 0):\n",
        "            if valid:\n",
        "              print(f\"Training loss after {e+1} epochs: {self.loss_during_training[-1]}, F1:{val_F1}, valid:{self.valid_loss_during_training[-1]}\")\n",
        "            else:\n",
        "              print(f\"Training loss after {e+1} epochs: {self.loss_during_training[-1]}\")\n",
        "            # We save model parameters  \n",
        "            torch.save(self.state_dict(), self.saved_files+'_epoch_'+str(e+1)+'.pth')\n",
        "\n",
        "    def evaluate(self, X, load = None, save= None):\n",
        "      \n",
        "      if load is not None:\n",
        "        state_dict = torch.load(load)\n",
        "        self.load_state_dict(state_dict)\n",
        "      with torch.no_grad():\n",
        "        self.eval()\n",
        "        pred_classes = [torch.argmax(self.forward(self.set_type_test(X[k,:]))) for k in range(X.shape[0])]\n",
        "        pred_classes = np.array(pred_classes)\n",
        "        ids = np.arange(len(pred_classes))\n",
        "        results = pd.DataFrame({'ID': ids, 'Pred_Class': pred_classes})\n",
        "        if save is not None:\n",
        "          results.to_csv(save, index=False)\n",
        "      return results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF7N3No3-53R",
        "outputId": "2ee7e9a2-2e62-44b7-ae30-bc2c9bee440c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-a3edb5bad552>:40: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.logsoftmax(x)\n"
          ]
        }
      ],
      "source": [
        "#rnn = RNN_with_train(64,16, lr = 0.001, batch_size = 64) \n",
        "rnn.trainloop(X, y,False, epochs=10, print_every=1) # idk how many epochs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test dataset preproccesing"
      ],
      "metadata": {
        "id": "Sit2u7Jnja0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "d3RzTLiyIbxj"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv('drive/MyDrive/Test_set.csv')\n",
        "df2.fillna(0, inplace = True)\n",
        "ids = df2['ID']\n",
        "X_test = df2.drop(['ID'], axis=1)\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "def expand_linear(time_series):\n",
        "  left = 0\n",
        "  right = 0\n",
        "  for k in range(1, len(time_series)):\n",
        "    if time_series[k] == 0:\n",
        "      left = time_series[k-1]\n",
        "      l = 0\n",
        "      while time_series[k+l] == 0:\n",
        "        l+=1\n",
        "        if len(time_series) == k+l:\n",
        "          return time_series\n",
        "      right = time_series[k+l]\n",
        "      time_series[k: k+l] = np.linspace(left, right, num=l+2)[1:(l+1)]\n",
        "  return time_series\n",
        "  # Scale but no 0s\n",
        "#nonX_test = X_test.reshape(-1)\n",
        "#nonX_test = nonX_test[nonX_test!=0]\n",
        "mean = 0.2949385572269969\n",
        "std = 0.22667829935749878\n",
        "for r in range(X_test.shape[0]):\n",
        "  for c in range(X_test.shape[1]):\n",
        "    if X_test[r,c] != 0:\n",
        "      X_test[r,c] -= mean\n",
        "X_test = X_test/std\n",
        "\n",
        "for k in range(X_test.shape[0]):\n",
        "  expand_linear(X_test[k,:])\n",
        "\n",
        "# X_test is the data after preprocessing in a numpy array"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "WAR9FY5tjfpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "s-oL5dlaSsO2"
      },
      "outputs": [],
      "source": [
        "rnn = RNN_with_train(128,64, lr = 0.0003, batch_size = 32) \n",
        "rnn.evaluate(X_test, load = \"drive/MyDrive/saved_models/_epoch_8.pth\", save = 'works.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparison to the best solution \n",
        "# You need at least 0.88 score to upload to kaggle "
      ],
      "metadata": {
        "id": "0tV8CjO4jhWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ICUjT2wo0HJf"
      },
      "outputs": [],
      "source": [
        "gabriele = pd.read_csv('sample_submission_deep.csv')\n",
        "print(sum(gabriele[\"Pred_Class\"] == results[\"Pred_Class\"])) \n",
        "ratio_gabriele = gabriele[\"Pred_Class\"].value_counts()\n",
        "#ratio = np.array(pd.Series(y).value_counts()/X.shape[0]*22000)\n",
        "ratio_est = results[\"Pred_Class\"].value_counts()\n",
        "df_ratio = pd.DataFrame({\"gabriele\":ratio_gabriele, \"current\": ratio_est})\n",
        "print(multiclass_f1_score(torch.tensor(results[\"Pred_Class\"]), torch.tensor(gabriele[\"Pred_Class\"]), num_classes=5, average = \"macro\"))\n",
        "df_ratio"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}