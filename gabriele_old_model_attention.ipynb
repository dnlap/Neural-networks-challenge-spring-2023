{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HoyusLaITNtN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15ab46a9-c625-4985-9db6-e36b0db9a03b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torcheval\n",
            "  Downloading torcheval-0.0.6-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.4/158.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.5.0)\n",
            "Collecting torchtnt>=0.0.5\n",
            "  Downloading torchtnt-0.1.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (1.22.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (2023.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (23.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (2.0.0+cu118)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (2.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (4.65.0)\n",
            "Collecting pyre-extensions\n",
            "  Downloading pyre_extensions-0.0.30-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (67.7.2)\n",
            "Collecting typing-inspect\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.54.0)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.27.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (3.4.3)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (0.40.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (3.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (1.11.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtnt>=0.0.5->torcheval) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtnt>=0.0.5->torcheval) (16.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (5.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (1.16.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->torchtnt>=0.0.5->torcheval) (1.3.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->torchtnt>=0.0.5->torcheval) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtnt>=0.0.5->torcheval) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->torchtnt>=0.0.5->torcheval) (3.2.2)\n",
            "Installing collected packages: mypy-extensions, typing-inspect, pyre-extensions, torchtnt, torcheval\n",
            "Successfully installed mypy-extensions-1.0.0 pyre-extensions-0.0.30 torcheval-0.0.6 torchtnt-0.1.0 typing-inspect-0.8.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from numpy import random\n",
        "\n",
        "!pip install torcheval\n",
        "from torcheval.metrics.functional import multiclass_f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Train_set.csv')"
      ],
      "metadata": {
        "id": "Uh_-XBESTcRX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linearly expand\n",
        "def expand_linear(time_series):\n",
        "  left = 0\n",
        "  right = 0\n",
        "  for k in range(1, len(time_series)):\n",
        "    if time_series[k] == 0:\n",
        "      left = time_series[k-1]\n",
        "      l = 0\n",
        "      while time_series[k+l] == 0:\n",
        "        l+=1\n",
        "        if len(time_series) == k+l:\n",
        "          return time_series\n",
        "      right = time_series[k+l]\n",
        "      time_series[k: k+l] = np.linspace(left, right, num=l+2)[1:(l+1)]\n",
        "  return time_series"
      ],
      "metadata": {
        "id": "wmtWAmvgTcvJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "So7R6NCFiHOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple idea of putting 0\n",
        "df.fillna(0, inplace = True)\n",
        "# Separate the ID and class columns from the input features\n",
        "ids = df['ID']\n",
        "y = df['Class']\n",
        "y = np.array(y)\n",
        "X = df.drop(['ID', 'Class'], axis=1)\n",
        "X = np.array(X)\n",
        "\n",
        "# Get lengths\n",
        "lengths = [np.trim_zeros(X[k, :], 'b').size for k in range(len(X))]\n",
        "lengths = np.array(lengths) -1\n",
        "# Expand \n",
        "for k in range(X.shape[0]):\n",
        "  expand_linear(X[k,:])\n",
        "\n",
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# valid set\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25)"
      ],
      "metadata": {
        "id": "9pS7P2GLiJia"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the preprocessed data to PyTorch tensors\n",
        "X_tensor = torch.from_numpy(X).float()\n",
        "y_tensor = torch.from_numpy(y).long()\n",
        "\n",
        "# Create a PyTorch DataLoader to handle batching and shuffling of the data\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "2yEwe8wWjLuk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, lengths, output_size = 5, lr=0.005):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.attention = nn.MultiheadAttention(embed_dim = hidden_size, num_heads = 1, batch_first = True)\n",
        "\n",
        "        self.lengths = lengths\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr)\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.attention(out[:,self.lengths,:], out, out)[0]\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "    def trainloop(self, num_epochs=40):\n",
        "\n",
        "      # Initialize the model and move it to the device\n",
        "\n",
        "      # Define the loss function and optimizer\n",
        "\n",
        "\n",
        "      # Train the model\n",
        "      for epoch in range(num_epochs):\n",
        "          for X_batch, y_batch in dataloader:\n",
        "              \n",
        "              \n",
        "              X_batch = X_batch.view([X_batch.shape[0],X_batch.shape[1],1]).to(self.device)\n",
        "              y_batch = y_batch.to(self.device)\n",
        "              running_loss = 0.\n",
        "              # Zero out the gradients\n",
        "              self.optimizer.zero_grad()\n",
        "              self.train()\n",
        "              # Forward pass\n",
        "              outputs = self.forward(X_batch)\n",
        "              loss = self.criterion(outputs, y_batch)\n",
        "  \n",
        "              # Backward pass and optimization\n",
        "              loss.backward()\n",
        "              self.optimizer.step()\n",
        "\n",
        "              running_loss += loss.item()\n",
        "          \n",
        "          # Print the loss and validation accuracy at the end of each epoch\n",
        "          with torch.no_grad():\n",
        "              total_loss = 0\n",
        "              total_correct = 0\n",
        "              total_samples = 0\n",
        "              for X_val, y_val in dataloader:\n",
        "                  X_val = X_val.to(self.device)\n",
        "                  y_val = y_val.to(self.device)\n",
        "                  outputs = self.forward(X_val)\n",
        "                  total_loss += self.criterion(outputs, y_val).item() * X_val.shape[0]\n",
        "                  total_correct += (outputs.argmax(dim=1) == y_val).sum().item()\n",
        "                  total_samples += X_val.shape[0]\n",
        "              val_loss = total_loss / total_samples\n",
        "              val_acc = total_correct / total_samples\n",
        "              val_F1 = multiclass_f1_score(outputs, y_val, num_classes=5)\n",
        "\n",
        "          print(f\"Epoch {epoch+1}/{num_epochs}: train_loss={loss.item():.4f} val_loss={val_loss:.4f} val_acc={val_acc:.4f} val_F1={val_F1:.4f}\")"
      ],
      "metadata": {
        "id": "7yTC6DfsiwNo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMModel(input_size=1, hidden_size=128, num_layers=1, lengths = lengths)\n",
        "model.trainloop(num_epochs = 1)"
      ],
      "metadata": {
        "id": "TKk1VXhOn2uT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test data into a pandas DataFrame\n",
        "test_data = pd.read_csv(\"Test_set.csv\")\n",
        "\n",
        "# Impute NaN values with the median value of each column\n",
        "test_data.fillna(0, inplace=True)\n",
        "\n",
        "# Drop irrelevant columns\n",
        "test_data = test_data.drop(columns=[\"ID\"])\n",
        "\n",
        "# Expand \n",
        "for k in range(test_data.shape[0]):\n",
        "  expand_linear(test_data[k,:])\n",
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "test_data = scaler.fit_transform(test_data)\n",
        "\n",
        "# Reshape the input features into a 3D array for input to the LSTM\n",
        "#test_data = test_data.reshape(test_data.shape[0], test_data.shape[1], 1)\n",
        "\n",
        "# Convert the numpy array to a PyTorch tensor\n",
        "#test_tensor = torch.Tensor(test_data)\n",
        "\n",
        "# Create a DataLoader object for the test data\n",
        "#test_loader = torch.utils.data.DataLoader(test_tensor, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "WluRMMUatz56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_classes = [torch.argmax(model.forward(test_data[k,:])) for k in range(test_data.shape[0])]\n",
        "pred_classes = np.array(pred_classes)\n",
        "ids = np.arange(len(pred_classes))\n",
        "results = pd.DataFrame({'ID': ids, 'Pred_Class': pred_classes})\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "results.to_csv('sub_30-04.csv', index=False)\n",
        "\n",
        "# 0 class\n",
        "sum(pred_classes ==0)"
      ],
      "metadata": {
        "id": "CoVmxZRwvEhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### NOT USED\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Create an empty list to store the predicted classes\n",
        "pred_classes = []\n",
        "\n",
        "# Loop through the test data in batches using the test loader\n",
        "for X_batch in test_loader:\n",
        "    # Move the batch to the device\n",
        "    #X_batch = X_batch.to(device)\n",
        "\n",
        "    # Compute the model's predicted class for the batch\n",
        "    outputs = model.forward(X_batch)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Convert the predicted class tensor to a numpy array\n",
        "    predicted = predicted.numpy()\n",
        "\n",
        "    # Append the predicted classes to the list\n",
        "    pred_classes.append(predicted)\n",
        "\n",
        "# Convert the list of predicted classes to a numpy array\n",
        "pred_classes = np.concatenate(pred_classes)\n",
        "\n",
        "# Create a new pandas DataFrame with the predicted classes and an ID column (if necessary)\n",
        "ids = np.arange(len(pred_classes))\n",
        "df = pd.DataFrame({'ID': ids, 'Pred_Class': pred_classes})\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "df.to_csv('submission1.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "sat6DNhhuXI5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
